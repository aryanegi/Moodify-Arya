# ğŸµ Moodify â€“ Emotion-Based Music Recommendation System

**Moodify** is an innovative web application that recommends and plays music based on the user's **facial expression**. It combines facial emotion detection with music streaming via the **Spotify API** to enhance the user's experience through personalized mood-based playlists.

---

## ğŸ’¡ Project Idea

Traditional music players require users to search and play music manually. Moodify proposes a smart solution â€” by analyzing the user's facial emotion through a webcam image, the system automatically plays a playlist that matches the detected mood using **Machine Learning** and **Spotify integration**.

---

## âš™ï¸ Tech Stack

- **Frontend**: HTML5, CSS3, JavaScript (via Flask templates)
- **Backend**: Flask (Python)
- **Machine Learning**: TensorFlow, Keras
- **Computer Vision**: OpenCV
- **Spotify Integration**: Spotipy (Python wrapper for the Spotify Web API)
- **Environment Management**: Python-Dotenv
- **Model File**: Pre-trained emotion detection model (`model.h5`) and Haar Cascade (`haarcascade_frontalface_default.xml`)

---

## ğŸ§  Core Features

- ğŸ­ Detects emotions from user's uploaded facial image (angry, happy, sad, neutral, etc.)
- ğŸ¶ Automatically generates and plays a personalized Spotify playlist based on the detected emotion
- ğŸ“¸ Real-time or static image-based emotion capture using OpenCV
- ğŸ§  Uses a trained CNN model to classify emotions from facial images

---

## ğŸ“ Project Structure

Moodify Final/
â””â”€â”€ Moodify/
    â””â”€â”€ moodify/
        â”œâ”€â”€ app.py
        â”œâ”€â”€ emotion_detection.py
        â””â”€â”€ model/
            â”œâ”€â”€ model.h5
            â””â”€â”€ haarcascade_frontalface_default.xml